{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opencv-python in c:\\users\\dharm\\appdata\\roaming\\python\\python38\\site-packages (4.10.0.82)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\dharm\\appdata\\roaming\\python\\python38\\site-packages (from opencv-python) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.10.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "print(cv2.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('registered_faces'):\n",
    "    os.makedirs('registered_faces')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sample picture and learn how to recognize it.\n",
    "Modi_image = face_recognition.load_image_file(\"Modi.jpg\")\n",
    "Modi_face_encoding = face_recognition.face_encodings(Modi_image)[0]\n",
    "\n",
    "# Load a second sample picture and learn how to recognize it.\n",
    "Kohli_image = face_recognition.load_image_file(\"Kohli.jpg\")\n",
    "Kohli_face_encoding = face_recognition.face_encodings(Kohli_image)[0]\n",
    "\n",
    "Nihar_image = face_recognition.load_image_file(\"Nihar.jpg\")\n",
    "Nihar_face_encoding = face_recognition.face_encodings(Nihar_image)[0]\n",
    "\n",
    "# Create arrays of known face encodings and their names\n",
    "known_face_encodings = [\n",
    "    Modi_face_encoding,\n",
    "    Kohli_face_encoding,\n",
    "    Nihar_face_encoding\n",
    "]\n",
    "known_face_names = [\n",
    "    \"Modi\",\n",
    "    \"Kohli\",\n",
    "    \"Nihar\"\n",
    "]\n",
    "# Aadhaar details for the known faces\n",
    "aadhaar_details = {\n",
    "    \"Modi\": \"Aadhaar Details for Modi: [1234-5678-9101]\",\n",
    "    \"Kohli\": \"Aadhaar Details for Kohli: [2345-6789-1012]\",\n",
    "    \"Nihar\": \"Aadhaar Details for Nihar: [3456-7890-1123]\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.09965005,  0.01257287,  0.03549203, -0.05077933, -0.02275129,\n",
       "       -0.05707148, -0.00739357, -0.04482555,  0.17687564, -0.0691358 ,\n",
       "        0.12299565, -0.02379135, -0.20054556, -0.08880908,  0.00350207,\n",
       "        0.01744138, -0.16425145, -0.15290068, -0.00792788, -0.06312364,\n",
       "        0.04632288,  0.0254629 ,  0.06577305,  0.06097015, -0.21376604,\n",
       "       -0.30779284, -0.08107652, -0.21990243,  0.01530453, -0.13512173,\n",
       "       -0.00346159,  0.04897284, -0.20438799, -0.0503398 , -0.03567981,\n",
       "        0.10015926,  0.08204275, -0.04600226,  0.20110808,  0.00590375,\n",
       "       -0.14903857, -0.08944672, -0.04790143,  0.26564246,  0.05679313,\n",
       "       -0.02259418,  0.02646403, -0.01758976,  0.13822114, -0.21441488,\n",
       "        0.09875869,  0.13483532,  0.0633258 ,  0.00693662,  0.06015252,\n",
       "       -0.1252597 ,  0.04251543,  0.08185501, -0.21970846,  0.04835903,\n",
       "        0.04016885,  0.05355866,  0.02343511, -0.00812267,  0.17923084,\n",
       "        0.03975492, -0.09150098, -0.05622239,  0.05830463, -0.14951807,\n",
       "        0.05224718,  0.09438995, -0.11016693, -0.17236082, -0.23408325,\n",
       "        0.06323555,  0.37867135,  0.09509143, -0.08977627,  0.04483248,\n",
       "       -0.17120288, -0.09361386,  0.02573206,  0.00448586, -0.11625139,\n",
       "        0.17130214, -0.09101719,  0.14981115,  0.16104668,  0.01075218,\n",
       "       -0.002086  ,  0.16403568, -0.02972881,  0.03095176,  0.03922803,\n",
       "        0.02420433, -0.09551857,  0.01939262, -0.05611241,  0.09129041,\n",
       "        0.0697931 , -0.08607247, -0.01610657,  0.0877859 , -0.19828667,\n",
       "        0.05863162,  0.00874024, -0.12413052, -0.05172531,  0.00447932,\n",
       "       -0.15265799, -0.098929  ,  0.14840336, -0.26378542,  0.07623924,\n",
       "        0.15308665,  0.01232811,  0.17086989, -0.01273108,  0.01620078,\n",
       "       -0.03874727, -0.02677137, -0.13193606, -0.0103693 ,  0.11046927,\n",
       "        0.02571688,  0.03433613, -0.01239414])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Kohli_face_encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Stored faces and giving back their aadhar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aadhaar Details for Nihar: [3456-7890-1123]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 68\u001b[0m\n\u001b[0;32m     65\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVideo\u001b[39m\u001b[38;5;124m'\u001b[39m, frame)\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;66;03m# Hit 'q' on the keyboard to quit!\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     69\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Release handle to the webcam\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize some variables\n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "process_this_frame = True\n",
    "recognized_faces = set()  # Set to keep track of recognized faces\n",
    "\n",
    "# Capture video from the webcam\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Grab a single frame of video\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    # Only process every other frame of video to save time\n",
    "    if process_this_frame:\n",
    "        # Resize frame of video to 1/4 size for faster face recognition processing\n",
    "        small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "\n",
    "        # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
    "        rgb_small_frame = small_frame[:, :, ::-1]\n",
    "        \n",
    "        # Find all the faces and face encodings in the current frame of video\n",
    "        face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "\n",
    "        face_names = []\n",
    "        for face_encoding in face_encodings:\n",
    "            # See if the face is a match for the known face(s)\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            name = \"Unknown\"\n",
    "\n",
    "            # Use the known face with the smallest distance to the new face\n",
    "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "            best_match_index = np.argmin(face_distances)\n",
    "            if matches[best_match_index]:\n",
    "                name = known_face_names[best_match_index]\n",
    "\n",
    "            face_names.append(name)\n",
    "\n",
    "            # Print Aadhaar details if the face is recognized and not already printed\n",
    "            if name in aadhaar_details and name not in recognized_faces:\n",
    "                print(aadhaar_details[name])\n",
    "                recognized_faces.add(name)\n",
    "\n",
    "    process_this_frame = not process_this_frame\n",
    "\n",
    "    # Display the results\n",
    "    for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "        # Scale back up face locations since the frame we detected in was scaled to 1/4 size\n",
    "        top *= 4\n",
    "        right *= 4\n",
    "        bottom *= 4\n",
    "        left *= 4\n",
    "\n",
    "        # Draw a box around the face\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "        # Draw a label with a name below the face\n",
    "        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # Hit 'q' on the keyboard to quit!\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release handle to the webcam\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting new faces and storing their aadhar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import simpledialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered new face: Hardik\n",
      "Aadhaar Details for Hardik: 0011-0011-0011\n"
     ]
    }
   ],
   "source": [
    "# Initialize some variables\n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "process_this_frame = True\n",
    "recognized_faces = set()  # Set to keep track of recognized faces\n",
    "\n",
    "# Initialize Tkinter\n",
    "root = tk.Tk()\n",
    "root.withdraw()  # Hide the root window\n",
    "\n",
    "# Capture video from the webcam\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Grab a single frame of video\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    # Only process every other frame of video to save time\n",
    "    if process_this_frame:\n",
    "        # Resize frame of video to 1/4 size for faster face recognition processing\n",
    "        small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "\n",
    "        # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
    "        rgb_small_frame = small_frame[:, :, ::-1]\n",
    "        \n",
    "        # Find all the faces and face encodings in the current frame of video\n",
    "        face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "\n",
    "        if face_encodings:  # If at least one face encoding is found\n",
    "            face_encoding = face_encodings[0]  # Process only the first detected face\n",
    "\n",
    "            # See if the face is a match for the known face(s)\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            name = \"Unknown\"\n",
    "\n",
    "            # Use the known face with the smallest distance to the new face\n",
    "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "            best_match_index = np.argmin(face_distances)\n",
    "            if matches[best_match_index]:\n",
    "                name = known_face_names[best_match_index]\n",
    "\n",
    "            face_names = [name]\n",
    "\n",
    "            # Print Aadhaar details if the face is recognized and not already printed\n",
    "            if name in aadhaar_details and name not in recognized_faces and name != \"Nihar\":\n",
    "                print(aadhaar_details[name])\n",
    "                recognized_faces.add(name)\n",
    "            elif name == \"Unknown\":\n",
    "                # Show dialog box to register new face\n",
    "                response = simpledialog.askstring(\"Input\", \"Unknown face detected. Do you want to register this face? (yes/no)\", parent=root)\n",
    "                if response and response.lower() == \"yes\":\n",
    "                    new_name = simpledialog.askstring(\"Input\", \"Enter name:\", parent=root)\n",
    "                    new_aadhaar = simpledialog.askstring(\"Input\", \"Enter Aadhaar details:\", parent=root)\n",
    "                    if new_name and new_aadhaar:\n",
    "                        known_face_encodings.append(face_encoding)\n",
    "                        known_face_names.append(new_name)\n",
    "                        aadhaar_details[new_name] = f\"Aadhaar Details for {new_name}: {new_aadhaar}\"\n",
    "                        print(f\"Registered new face: {new_name}\")\n",
    "\n",
    "    process_this_frame = not process_this_frame\n",
    "\n",
    "    # Display the results\n",
    "    for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "        if name == \"Nihar\":\n",
    "            continue  # Skip drawing the box and label for Nihar\n",
    "        \n",
    "        # Scale back up face locations since the frame we detected in was scaled to 1/4 size\n",
    "        top *= 4\n",
    "        right *= 4\n",
    "        bottom *= 4\n",
    "        left *= 4\n",
    "\n",
    "        # Draw a box around the face\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "        # Draw a label with a name below the face\n",
    "        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # Hit 'q' on the keyboard to quit!\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release handle to the webcam\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for New data storage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\dharm\\AppData\\Roaming\\Python\\Python38\\site-packages\\~~mpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-intel 2.13.0 requires numpy<=1.24.3,>=1.22, but you have numpy 1.24.4 which is incompatible.\n",
      "tensorflow-intel 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.12.2 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting numpy==1.24.4\n",
      "  Using cached numpy-1.24.4-cp38-cp38-win_amd64.whl.metadata (5.6 kB)\n",
      "Using cached numpy-1.24.4-cp38-cp38-win_amd64.whl (14.9 MB)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.3\n",
      "    Uninstalling numpy-1.24.3:\n",
      "      Successfully uninstalled numpy-1.24.3\n",
      "Successfully installed numpy-1.24.4\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.24.4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.24.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "from tkinter import simpledialog, Tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "process_this_frame = True\n",
    "recognized_faces = set()  # Set to keep track of recognized faces\n",
    "\n",
    "# Initialize Tkinter\n",
    "root = Tk()\n",
    "root.withdraw()  # Hide the root window\n",
    "\n",
    "# Capture video from the webcam\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Grab a single frame of video\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    # Only process every other frame of video to save time\n",
    "    if process_this_frame:\n",
    "        # Resize frame of video to 1/4 size for faster face recognition processing\n",
    "        small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "\n",
    "        # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\n",
    "        rgb_small_frame = small_frame[:, :, ::-1]\n",
    "        \n",
    "        # Find all the faces and face encodings in the current frame of video\n",
    "        face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "\n",
    "        if face_encodings:  # If at least one face encoding is found\n",
    "            face_encoding = face_encodings[0]  # Process only the first detected face\n",
    "\n",
    "            # See if the face is a match for the known face(s)\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            name = \"Unknown\"\n",
    "\n",
    "            # Use the known face with the smallest distance to the new face\n",
    "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "            best_match_index = np.argmin(face_distances)\n",
    "            if matches[best_match_index]:\n",
    "                name = known_face_names[best_match_index]\n",
    "\n",
    "            face_names = [name]\n",
    "\n",
    "            # Print Aadhaar details if the face is recognized and not already printed\n",
    "            if name in aadhaar_details and name not in recognized_faces and name != \"Nihar\":\n",
    "                print(aadhaar_details[name])\n",
    "                recognized_faces.add(name)\n",
    "            elif name == \"Unknown\":\n",
    "                # Show dialog box to register new face\n",
    "                response = simpledialog.askstring(\"Input\", \"Unknown face detected. Do you want to register this face? (yes/no)\", parent=root)\n",
    "                if response and response.lower() == \"yes\":\n",
    "                    new_name = simpledialog.askstring(\"Input\", \"Enter name:\", parent=root)\n",
    "                    new_aadhaar = simpledialog.askstring(\"Input\", \"Enter Aadhaar details:\", parent=root)\n",
    "                    if new_name and new_aadhaar:\n",
    "                        known_face_encodings.append(face_encoding)\n",
    "                        known_face_names.append(new_name)\n",
    "                        aadhaar_details[new_name] = f\"Aadhaar Details for {new_name}: {new_aadhaar}\"\n",
    "                        print(f\"Registered new face: {new_name}\")\n",
    "\n",
    "                        # Save the new face image\n",
    "                        top, right, bottom, left = face_locations[0]\n",
    "                        top *= 4\n",
    "                        right *= 4\n",
    "                        bottom *= 4\n",
    "                        left *= 4\n",
    "                        face_image = frame[top:bottom, left:right]\n",
    "                        timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "                        face_image_path = os.path.join('registered_faces', f\"{new_name}_{timestamp}.jpg\")\n",
    "                        cv2.imwrite(face_image_path, face_image)\n",
    "                        \n",
    "                        # Save the new face data to a CSV file\n",
    "                        face_data = pd.DataFrame([[new_name, new_aadhaar, face_image_path]], columns=[\"Name\", \"Aadhaar\", \"Image_Path\"])\n",
    "                        csv_path = 'registered_faces_data.csv'\n",
    "                        if os.path.exists(csv_path):\n",
    "                            face_data.to_csv(csv_path, mode='a', header=False, index=False)\n",
    "                        else:\n",
    "                            face_data.to_csv(csv_path, mode='w', header=True, index=False)\n",
    "\n",
    "    process_this_frame = not process_this_frame\n",
    "\n",
    "    # Display the results\n",
    "    for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "        if name == \"Nihar\":\n",
    "            continue  # Skip drawing the box and label for Nihar\n",
    "        \n",
    "        # Scale back up face locations since the frame we detected in was scaled to 1/4 size\n",
    "        top *= 4\n",
    "        right *= 4\n",
    "        bottom *= 4\n",
    "        left *= 4\n",
    "\n",
    "        # Draw a box around the face\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "\n",
    "        # Draw a label with a name below the face\n",
    "        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "    # Display the resulting image\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # Hit 'q' on the keyboard to quit!\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release handle to the webcam\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
